# Updated Threat Modeling Analysis for Screenshot-to-Code Using Attack Trees

## 1. Understand the Project

**Project Name**: Screenshot-to-Code

### Overview

Screenshot-to-Code is a tool that converts screenshots, mockups, and Figma designs into functional code using AI models. Users can upload an image or video recording of a website/UI and the tool will generate code in various frameworks like HTML+Tailwind, React, Vue, Bootstrap, or SVG. The project consists of a React/Vite frontend and a FastAPI backend that interfaces with AI models like Claude Sonnet 3.5, GPT-4o, and others.

### Key Components and Features

- **Frontend**: React/Vite-based web interface for uploading screenshots and viewing/editing generated code
- **Backend**: FastAPI server that handles API requests and AI model communication
- **LLM Integration**: Interfaces with various AI models (OpenAI, Anthropic, Google Gemini)
- **Image Processing**: Tools for handling and optimizing images for AI processing
- **Video Processing**: Converts video recordings into frames for UI code generation
- **Image Generation**: Optional integration with DALL-E or Replicate for generating placeholder images
- **Evaluation System**: Tools for rating and comparing the quality of code generated by different models
- **Screenshot API**: Integration with ScreenshotOne for capturing website screenshots
- **Multi-stack Support**: Generates code in various frameworks (HTML+Tailwind, React, Vue, Bootstrap, Ionic, SVG)

### Dependencies

- **External APIs**: OpenAI API, Anthropic API, Google Gemini API, Replicate API, ScreenshotOne API
- **Backend**: Python 3.10+, FastAPI, websockets, various Python libraries including moviepy for video processing
- **Frontend**: React, Vite, and various JavaScript dependencies
- **Deployment**: Docker for containerized deployment

## 2. Define the Root Goal of the Attack Tree

**Attacker's Ultimate Objective**: Compromise applications using Screenshot-to-Code by exploiting weaknesses in the project itself.

## 3. High-Level Attack Paths (Sub-Goals)

1. Steal API Keys and Resources
2. Exploit Input Validation Weaknesses
3. Attack AI Model Integrations
4. Perform Client-Side Attacks
5. Compromise Execution Environment

## 4. Visualize the Attack Tree

```
Root Goal: Compromise applications using Screenshot-to-Code by exploiting weaknesses in the project

[OR]
+-- 1. Steal API Keys and Resources
    [OR]
    +-- 1.1 Extract API keys from frontend
        [OR]
        +-- 1.1.1 Access browser storage
            [AND]
            +-- Execute XSS attack on the application
            +-- Extract API keys from localStorage
        +-- 1.1.2 Intercept keys during configuration
            [AND]
            +-- Position as man-in-the-middle
            +-- Capture HTTP traffic containing keys
    +-- 1.2 Abuse API proxy functionality
        [AND]
        +-- Configure malicious OpenAI proxy URL
        +-- Intercept requests to capture API keys
    +-- 1.3 Extract keys from logs or debug output
        [AND]
        +-- Enable debug mode (IS_DEBUG_ENABLED)
        +-- Access debug artifacts with exposed keys

+-- 2. Exploit Input Validation Weaknesses
    [OR]
    +-- 2.1 Exploit image upload vulnerabilities
        [OR]
        +-- 2.1.1 Upload malformed images
            [AND]
            +-- Create specially crafted malicious image
            +-- Trigger buffer overflow in image processing
        +-- 2.1.2 Path traversal via image metadata
            [AND]
            +-- Craft image with malicious metadata
            +-- Exploit weak file handling
    +-- 2.2 Upload malicious code for import
        [AND]
        +-- Create code with embedded payload
        +-- Import code through the interface
    +-- 2.3 WebSocket message tampering
        [AND]
        +-- Intercept WebSocket connection
        +-- Inject malicious data into stream
    +-- 2.4 Exploit video processing functionality
        [AND]
        +-- Create maliciously crafted video file
        +-- Trigger vulnerabilities in moviepy library
    +-- 2.5 Abuse screenshot API integration
        [AND]
        +-- Provide malicious URL to screenshot API
        +-- Execute server-side attack through rendered content

+-- 3. Attack AI Model Integrations
    [OR]
    +-- 3.1 Perform prompt injection attacks
        [OR]
        +-- 3.1.1 Direct prompt injection via images
            [AND]
            +-- Create screenshot with malicious prompts
            +-- Bypass prompt filtering
        +-- 3.1.2 Indirect prompt injection via alt text
            [AND]
            +-- Craft malicious alt text in imported code
            +-- Trigger AI to process the alt text
        +-- 3.1.3 Prompt injection via video frames
            [AND]
            +-- Create video with strategically placed prompt text
            +-- AI processes frames containing malicious instructions
    +-- 3.2 Manipulate AI to generate malicious code
        [AND]
        +-- Design crafted prompts to generate harmful code
        +-- Deploy generated exploits to victim applications
    +-- 3.3 Circumvent AI safety mechanisms
        [AND]
        +-- Study model filtering mechanisms
        +-- Craft inputs that bypass security checks

+-- 4. Perform Client-Side Attacks
    [OR]
    +-- 4.1 Inject XSS in generated code
        [AND]
        +-- Craft input that produces unsanitized code
        +-- Victim loads and executes the code
    +-- 4.2 Execute stored XSS attacks
        [AND]
        +-- Upload image/code that generates XSS payload
        +-- Victim views generated code with payload
    +-- 4.3 Exploit the frontend evaluation system
        [AND]
        +-- Upload malicious content to evaluation system
        +-- Trigger code execution in evaluation context

+-- 5. Compromise Execution Environment
    [OR]
    +-- 5.1 Exploit Docker configuration
        [AND]
        +-- Identify weaknesses in docker-compose.yml
        +-- Escape container to host environment
    +-- 5.2 Attack file system access
        [OR]
        +-- 5.2.1 Path traversal in evaluation file operations
            [AND]
            +-- Manipulate file paths in evaluation requests
            +-- Access unauthorized files on the server
        +-- 5.2.2 Exploit temporary file operations
            [AND]
            +-- Craft malicious video input
            +-- Exploit race conditions in temporary file handling
```

## 5. Assign Attributes to Each Node

| Attack Step | Likelihood | Impact | Effort | Skill Level | Detection Difficulty | Justification |
|---|---|---|---|---|---|---|
| 1. Steal API Keys and Resources | High | High | Medium | Medium | Medium | API keys are central to application functionality and are valuable targets |
| - 1.1 Extract API keys from frontend | High | High | Low | Medium | Medium | Keys appear to be stored in browser where they can be accessed |
| -- 1.1.1 Access browser storage | High | High | Low | Low | Medium | Keys stored in browser storage are easily accessible if XSS is achieved |
| -- 1.1.2 Intercept keys during configuration | Medium | High | Medium | Medium | Medium | Requires network positioning but keys must be transmitted |
| - 1.2 Abuse API proxy functionality | High | High | Low | Medium | High | Custom proxy URLs can be configured, enabling interception |
| - 1.3 Extract keys from logs or debug output | Medium | High | Medium | Medium | Medium | Debug mode exists and might log sensitive information |
| 2. Exploit Input Validation Weaknesses | Medium | High | Medium | Medium | Medium | Multiple input paths that could have validation flaws |
| - 2.1 Exploit image upload vulnerabilities | Medium | High | Medium | Medium | Medium | Image processing could have bugs that can be exploited |
| -- 2.1.1 Upload malformed images | Medium | High | Medium | High | Medium | Image processing library vulnerabilities could be exploitable |
| -- 2.1.2 Path traversal via image metadata | Low | High | Medium | High | Medium | Depends on how metadata is processed |
| - 2.2 Upload malicious code for import | High | Medium | Low | Medium | Low | Imported code functionality exists and can be misused |
| - 2.3 WebSocket message tampering | Medium | High | Medium | High | High | WebSockets used for streaming responses could be manipulated |
| - 2.4 Exploit video processing functionality | Medium | High | Medium | High | Medium | Video processing with moviepy could have vulnerabilities |
| - 2.5 Abuse screenshot API integration | Medium | High | Medium | Medium | High | ScreenshotOne API could be targeted with malicious URLs |
| 3. Attack AI Model Integrations | High | Critical | Low | Medium | High | Heavy reliance on external AI services creates attack surface |
| - 3.1 Perform prompt injection attacks | High | High | Low | Medium | High | AI models are susceptible to prompt injection |
| -- 3.1.1 Direct prompt injection via images | High | High | Low | Medium | High | Images with text can influence AI behavior |
| -- 3.1.2 Indirect prompt injection via alt text | High | High | Low | Medium | High | Alt texts are processed by AI and can inject commands |
| -- 3.1.3 Prompt injection via video frames | High | High | Low | Medium | High | Video frames are directly fed to AI models without filtering |
| - 3.2 Manipulate AI to generate malicious code | High | Critical | Low | Medium | Medium | AI could be tricked into generating harmful code for end users |
| - 3.3 Circumvent AI safety mechanisms | Medium | High | Medium | High | High | Safety measures may have bypasses |
| 4. Perform Client-Side Attacks | High | Medium | Low | Medium | Medium | Web-based application vulnerable to client-side attacks |
| - 4.1 Inject XSS in generated code | High | Medium | Low | Medium | Medium | Generated code may contain unsanitized user input |
| - 4.2 Execute stored XSS attacks | High | Medium | Low | Medium | Medium | Stored content could include executable code |
| - 4.3 Exploit the frontend evaluation system | Medium | High | Medium | High | High | Evaluation system processes untrusted content |
| 5. Compromise Execution Environment | Low | Critical | High | High | Medium | Difficult but highly impactful if achieved |
| - 5.1 Exploit Docker configuration | Low | Critical | High | High | Medium | Docker deployment could have security misconfigurations |
| - 5.2 Attack file system access | Low | High | High | High | Medium | Would require specific file operation vulnerabilities |
| -- 5.2.1 Path traversal in evaluation file operations | Medium | High | Medium | High | Medium | Eval system reads files with user-controlled input paths |
| -- 5.2.2 Exploit temporary file operations | Low | High | High | High | Medium | Temporary files created during video processing |

## 6. Analyze and Prioritize Attack Paths

### High-Risk Paths

1. **API Key Theft via Browser Storage (1.1.1)**:
   - **Justification**: High likelihood, high impact, low effort. API keys stored in browser storage can be easily extracted if an attacker can execute JavaScript in the context of the application.

2. **API Proxy Abuse (1.2)**:
   - **Justification**: High likelihood, high impact, low effort. The application allows custom API proxy URLs to be configured, which could be exploited to route API calls through an attacker-controlled server.

3. **Prompt Injection via Screenshots or Video Frames (3.1.1, 3.1.3)**:
   - **Justification**: High likelihood, high impact, low effort. AI models can be manipulated by text contained in screenshots or video frames, potentially leading to unauthorized disclosure or malicious code generation.

4. **Generating Malicious Code through AI Manipulation (3.2)**:
   - **Justification**: High likelihood, critical impact, low effort. If an attacker can craft prompts that cause the AI to generate malicious code, end users may deploy this code without realizing it contains exploits.

5. **XSS in Generated Code (4.1)**:
   - **Justification**: High likelihood, medium impact, low effort. If the application doesn't properly sanitize inputs before generating code, it could create code with embedded XSS payloads.

6. **Path Traversal in Evaluation System (5.2.1)**:
   - **Justification**: Medium likelihood, high impact, medium effort. The evaluation file operations use user-controlled paths that could potentially be manipulated for path traversal attacks.

### Critical Nodes

1. **API Key Management (1.1, 1.2)**: API keys are central to the application's functionality and represent high-value targets. Compromising them allows an attacker to use resources at the expense of the victim or access private data.

2. **AI Model Manipulation (3.2)**: The ability to make AI models generate malicious code is especially dangerous as this malicious code would then be deployed by unsuspecting users.

3. **Video Processing (2.4, 3.1.3)**: The video processing feature introduces new attack vectors, both for library exploitation and for prompt injection through sequential frames.

4. **Client-Side Security (4.1, 4.2)**: Vulnerabilities in client-side security could lead to cross-site scripting attacks that compromise user data or hijack sessions.

5. **File System Operations (5.2)**: The evaluation system and temporary file operations provide potential paths to file system access that could be exploited.

## 7. Develop Mitigation Strategies

### For API Key Theft:

1. **Implement a Server-Side Proxy**: Instead of storing API keys in the frontend, implement a backend proxy service that makes API calls on behalf of the client.

2. **Implement Secure Storage**: If client-side storage is necessary, use more secure methods than localStorage (such as HTTPOnly cookies for session identifiers).

3. **Validate Proxy URLs**: If custom API proxy URLs are allowed, implement strict validation to prevent malicious configurations.

4. **Sanitize Debug Output**: Ensure API keys and other sensitive data are masked in logs and debug output.

### For Input Validation Weaknesses:

1. **Implement Strict Input Validation**: Validate all user inputs, including images, videos, code imports, and WebSocket messages.

2. **Use Safe Image and Video Processing**: Implement secure handling methods to prevent exploitation of processing vulnerabilities.

3. **Sanitize Imported Code**: Thoroughly sanitize and validate any imported code before processing.

4. **Secure WebSocket Connections**: Validate all WebSocket messages and implement proper authentication.

5. **Validate Screenshot URLs**: Implement URL validation for the screenshot API to prevent malicious URLs.

### For AI Model Attacks:

1. **Implement Prompt Sanitization**: Filter or sanitize prompts sent to AI models to prevent injection attacks.

2. **Scan Video Frames for Text**: Implement OCR to detect and filter potential prompt injection attempts in video frames.

3. **Review Generated Code**: Implement automated scanning of AI-generated code for security issues before presenting it to users.

4. **Add Content Warnings**: Warn users about potential risks of using AI-generated code without review.

5. **Implement Model Guardrails**: Configure AI models with stricter safety settings to prevent generation of harmful content.

### For Client-Side Security:

1. **Implement Content Security Policy (CSP)**: Use CSP headers to prevent execution of unauthorized scripts.

2. **Sanitize Generated Code**: Ensure all generated code is properly sanitized to prevent XSS vulnerabilities.

3. **Regular Security Testing**: Perform regular security testing specifically targeting XSS vulnerabilities in generated code.

### For Execution Environment:

1. **Secure Docker Configuration**: Follow Docker security best practices, including running containers with least privilege.

2. **Implement Proper File Access Controls**: Ensure file operations use proper permissions and validate paths to prevent traversal.

3. **Secure Temporary File Operations**: Implement secure handling of temporary files created during video processing.

4. **Validate File Paths**: Implement strict validation of file paths in the evaluation system to prevent path traversal.

## 8. Summarize Findings

The Screenshot-to-Code project has several potential security vulnerabilities that attackers could exploit. The most critical risks involve:

1. **API Key Management**: The application requires third-party API keys which are vulnerable to theft and misuse. Storing keys in browser storage or transmitting them directly from the client creates significant security risk.

2. **AI Model Vulnerabilities**: The reliance on AI models introduces risks like prompt injection attacks and generation of malicious code. An attacker could craft inputs (images or videos) that manipulate the AI to produce harmful outputs.

3. **Video Processing**: The addition of video processing introduces new attack vectors, including library vulnerabilities in moviepy and the potential for sequential frame-based prompt injection attacks.

4. **Client-Side Security**: As a web application, it faces common web vulnerabilities like XSS, particularly through the generated code which might contain unsanitized content.

5. **File System Operations**: The evaluation system and temporary file handling in video processing could potentially be exploited to access unauthorized files on the server.

The highest priority recommendation is to implement server-side handling of API keys rather than storing them client-side. Additionally, implementing thorough input validation for both images and videos, sanitizing AI-generated code, and addressing file system operations would significantly improve the project's security posture.

## 9. Questions & Assumptions

### Questions:
1. How are API keys stored in the hosted version (screenshottocode.com) compared to the open-source version?
2. Is there any sanitization of generated code to prevent XSS vulnerabilities?
3. What validation is performed on image and video uploads and imported code?
4. Are there any rate limiting mechanisms to prevent abuse of AI services?
5. How are file paths in the evaluation system validated to prevent path traversal?

### Assumptions:
1. API keys are stored in browser storage based on the frontend settings dialog references.
2. WebSocket connections are used for streaming AI responses but may not implement comprehensive message validation.
3. Debug mode can expose sensitive information if enabled.
4. The frontend appears to display generated code directly, which could execute if it contains malicious scripts.
5. Docker is used for deployment as indicated by Dockerfile and docker-compose.yml.
6. Video processing creates temporary files that could potentially be exploited.
7. The evaluation system uses user-controlled file paths without strict validation.
