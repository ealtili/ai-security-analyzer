# ATTACK SURFACE ANALYSIS - Screenshot-to-Code App

## API Key Exposure

- **Description**: The application requires API keys for OpenAI, Anthropic, and other services. These keys grant access to paid services and could be misused if exposed.

- **How screenshot-to-code contributes**: The application stores API keys in `.env` files and allows users to set them through a UI. According to the README, "Your key is only stored in your browser. Never stored on our servers." The code in `generate_code.py` shows that keys are accepted from both environment variables and client-side user input.

- **Example**: An attacker who gains access to a user's computer could extract the API keys from the `.env` files or from browser storage. Alternatively, malicious code injected into the application could steal these keys.

- **Impact**: Unauthorized use of API keys leading to financial losses as the attacker could use paid AI services at the original user's expense.

- **Risk Severity**: High

- **Current Mitigations**: The application keeps API keys on the client side only, reducing server-side exposure. The readme states that keys are "only stored in your browser. Never stored on our servers."

- **Missing Mitigations**:
  - Encourage users to set up usage limits on their API keys
  - Implement key rotation recommendations
  - Encrypt API keys in local storage
  - Provide clear instructions on how to revoke compromised keys

## Cross-Site Scripting (XSS)

- **Description**: The application generates HTML, CSS, and JavaScript code that is rendered in a browser, potentially enabling XSS attacks.

- **How screenshot-to-code contributes**: Generated code is displayed and possibly executed in the application preview functionality. The `generate_code.py` file shows that code generated by AI models is extracted and sent back to the client without sanitization.

- **Example**: If the AI generates code containing malicious JavaScript that is then executed in the browser, it could perform actions such as stealing session data or performing unauthorized actions.

- **Impact**: Session hijacking, data theft, unauthorized actions performed on behalf of the user.

- **Risk Severity**: High

- **Current Mitigations**: There are no clearly identified mitigations in the code. The application appears to rely on the AI models to generate safe code, which is not a strong mitigation.

- **Missing Mitigations**:
  - Sanitize generated code before rendering
  - Use Content Security Policy (CSP) to restrict what resources can be loaded
  - Render generated code in an isolated iframe with appropriate sandboxing
  - Implement output encoding when displaying generated code

## Prompt Injection

- **Description**: The application is vulnerable to prompt injection attacks where malicious inputs manipulate the AI to generate harmful content or bypass restrictions.

- **How screenshot-to-code contributes**: The app directly passes user inputs (screenshots, text, videos) to AI models as part of prompts, as seen in both `generate_code.py` and `video/utils.py`.

- **Example**: An attacker could craft a screenshot containing text that instructs the AI to ignore previous constraints and generate malicious code.

- **Impact**: Bypassing safety measures, generating harmful content, potential code injection.

- **Risk Severity**: High

- **Current Mitigations**: The application relies on the AI providers' built-in safeguards against prompt injection.

- **Missing Mitigations**:
  - Implement prompt sanitization
  - Use structured prompts that are less vulnerable to injection
  - Monitor and audit generated content for signs of prompt injection
  - Stay updated on prompt injection techniques and countermeasures

## Path Traversal

- **Description**: Path traversal vulnerabilities allow attackers to access files and directories outside of intended boundaries by manipulating path references.

- **How screenshot-to-code contributes**: In `evals.py`, the application accepts user-provided folder paths and reads files from these paths without proper path sanitization or validation.

- **Example**: An attacker could provide paths like `../../../etc/passwd` to access sensitive system files, or traverse to configuration files containing API keys or secrets.

- **Impact**: Unauthorized access to sensitive files, information disclosure, potential system compromise.

- **Risk Severity**: High

- **Current Mitigations**: The code validates that provided folders exist but does not prevent path traversal techniques.

- **Missing Mitigations**:
  - Implement strict path validation that prevents directory traversal
  - Use a whitelist of allowed directories
  - Sandbox file operations to a specific, safe directory
  - Use path normalization and check for path traversal sequences

## Image Processing Vulnerabilities

- **Description**: The application processes user-uploaded images and videos, which could exploit vulnerabilities in image processing libraries.

- **How screenshot-to-code contributes**: The app uses libraries for image and video processing in `video/utils.py`, which processes video files into frames using libraries like moviepy and PIL.

- **Example**: A maliciously crafted image or video file could exploit vulnerabilities in these libraries, potentially leading to code execution.

- **Impact**: Remote code execution, denial of service, or information disclosure.

- **Risk Severity**: Medium

- **Current Mitigations**: The code performs basic processing of images and videos, but no explicit security validations are present.

- **Missing Mitigations**:
  - Keep image processing libraries updated
  - Implement stricter validation of input images and videos (file type, size, content)
  - Run image processing in a sandboxed environment
  - Limit resources available to image processing functions

## Server-Side Request Forgery (SSRF)

- **Description**: The application makes requests to external services, which could be manipulated to target internal services or extract sensitive information.

- **How screenshot-to-code contributes**: The app allows configuring the OpenAI base URL (`OPENAI_BASE_URL` in config.py). Additionally, in `screenshot.py`, the application takes a user-provided URL and sends it to an external screenshot service.

- **Example**: An attacker might configure the OpenAI base URL to point to internal services, or provide a URL to the screenshot service that accesses internal network resources.

- **Impact**: Access to internal services, potential circumvention of network security controls, information disclosure.

- **Risk Severity**: Medium

- **Current Mitigations**: For the OpenAI base URL, the code disables user-specified base URLs in production environments.

- **Missing Mitigations**:
  - Validate and sanitize all URLs to ensure they point to legitimate external services
  - Implement network-level controls to prevent access to internal resources
  - Use allowlists for permitted domains
  - Implement proper error handling that doesn't leak information about internal services

## Cross-Site WebSocket Hijacking

- **Description**: WebSocket connections may be vulnerable to cross-site attacks if proper origin validation is not implemented.

- **How screenshot-to-code contributes**: The application implements a WebSocket endpoint in `generate_code.py` for streaming code generation results, but lacks explicit origin validation.

- **Example**: An attacker could create a malicious website that establishes a WebSocket connection to the screenshot-to-code application, potentially accessing sensitive data or performing actions on behalf of the user.

- **Impact**: Unauthorized access to WebSocket communications, potential data theft or unauthorized actions.

- **Risk Severity**: Medium

- **Current Mitigations**: No obvious mitigations are implemented in the WebSocket handling code.

- **Missing Mitigations**:
  - Implement proper origin validation for WebSocket connections
  - Use authentication tokens for WebSocket connections
  - Implement CSRF protections for WebSocket establishment
  - Set appropriate timeouts for WebSocket connections

## Resource Exhaustion

- **Description**: Resource exhaustion attacks aim to consume excessive system resources (CPU, memory, disk) to degrade performance or cause denial of service.

- **How screenshot-to-code contributes**: Several features could be abused for resource consumption, including video processing in `video/utils.py` and parallel AI model execution in `generate_code.py`. The evals feature in `evals.py` also allows running evaluations on multiple models without apparent limits.

- **Example**: An attacker could upload extremely large or malformed videos, or trigger many simultaneous AI evaluations to consume server resources.

- **Impact**: Service degradation, increased costs for cloud resources, potential denial of service.

- **Risk Severity**: Medium

- **Current Mitigations**: The video processing has a target number of screenshots limit, but other resource-intensive operations lack clear rate limiting.

- **Missing Mitigations**:
  - Implement rate limiting for resource-intensive operations
  - Set maximum file sizes for uploads
  - Limit parallel processing
  - Monitor and automatically scale resources based on demand
  - Implement timeouts for long-running operations
